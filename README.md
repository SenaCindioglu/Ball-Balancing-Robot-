Ball Balancing Robot
A sophisticated self-balancing robotic platform that maintains dynamic equilibrium on top of a spherical surface through integrated computer vision, advanced control algorithms, and real-time firmware execution. This project demonstrates the practical application of control theory, image processing, and embedded systems in managing an inherently unstable inverse pendulum system with omnidirectional motion constraints.
Computer Vision Module:
The vision system captures real-time camera frames to extract critical spatial information about the robot's state. Using OpenCV-based image processing, the module detects the white ball's position within the frame and identifies the robot's orientation markers. The system performs color-space conversion and contour detection to precisely locate the ball center, calculating its pixel coordinates relative to a reference frame. Advanced filtering techniques reduce noise from lighting variations and motion blur. The processed vision data outputs the ball's absolute position (x, y coordinates) and the robot's angular orientation, which serves as the primary feedback for the control loop. This real-time perception runs at high frame rates to ensure responsive corrections.
PID Controller Implementation:
The PID (Proportional-Integral-Derivative) control algorithm forms the core of the stability system, processing vision feedback to generate motor commands. The controller receives error signals representing the deviation between the current ball position and the desired equilibrium point (typically frame center). The proportional component generates immediate corrective action proportional to current error magnitude, the integral component eliminates steady-state error by accumulating past deviations, and the derivative component predicts future error trends to prevent oscillation and overshoot. Tuned PID parameters (Kp, Ki, Kd) balance responsiveness with stability. The algorithm runs in a tight control loop, calculating corrections for both X and Y axes independently to manage the robot's pitch and roll. The output produces motor command values that drive the stepper or brushless motors in opposite directions to tilt the platform and shift the ball's position back toward equilibrium.
STM32 Microcontroller Firmware:
The STM32 microcontroller executes low-level motor control and receives high-level commands from the computer vision system via serial communication (UART). The firmware implements PWM (Pulse Width Modulation) drivers for precise motor speed and direction control, managing motor acceleration curves and current limiting to prevent hardware damage. It receives motor command values from the PID controller and translates them into appropriate PWM signals sent to motor drivers (like L298N or similar H-bridge modules). The STM32 also handles sensor integration, processing IMU data (accelerometer/gyroscope) for hybrid feedback and cross-validation with vision data. The firmware maintains a control loop running at deterministic intervals (typically 50-100 Hz), ensuring reliable timing for motor pulses and serial data reception. Additionally, it manages target waypoint reception from the GUI, storing trajectory commands and executing sequential movements for autonomous navigation.
GUI Control Dashboard:
The graphical interface provides intuitive waypoint definition and real-time system monitoring. Operators can set target positions on a virtual representation of the arena, which are transmitted to the STM32 via serial protocol. The GUI displays live computer vision feedback, showing the detected ball position, robot orientation, and current error metrics. Real-time plots visualize PID controller outputs, motor commands, and system performance metrics. The interface includes tuning sliders for PID parameters (Kp, Ki, Kd), enabling dynamic optimization without code recompilation. Status indicators show serial connection state, firmware health, and emergency stop functionality.
System Architecture & Data Flow:
Camera → Vision Processing (OpenCV) → Ball/Robot Detection → Position Coordinates → PID Controller → Motor Commands → STM32 UART Interface → PWM Drivers → Motors → Physical Motion → Feedback Loop. The GUI runs on the host computer, receiving vision data for display while sending waypoint targets to the embedded system.
Key Challenges Addressed:
Managing inverse pendulum instability through tight feedback control, compensating for ball rolling dynamics in real-time, filtering noisy vision data under varying lighting conditions, and coordinating multi-axis motor control for precise balancing.


https://github.com/user-attachments/assets/d9fc9d44-12c5-4ad0-847a-762982dbec53


https://github.com/user-attachments/assets/8340e065-8bae-4b92-afb5-ee4f54b2047f

<img width="1199" height="841" alt="Screenshot 2025-10-12 155036" src="https://github.com/user-attachments/assets/fb8edf5a-6342-434e-abc9-5355b4d044a4" />
